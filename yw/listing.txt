######################################################################
@begin clean_name_date_log
@in input1_data @uri file:{input1_data_file_name}
@param local_authority_source @uri {local_authority_source_file_name}
@out log1_data @uri file:{log1_data_file_name}
@out output2_data  @uri file:{output2_data_file_name}
@out log2_data @uri file:{log2_data_file_name}
@begin validate_scientificName_field_of_data
@param local_authority_source @uri {local_authority_source_file_name}
@in input1_data @uri file:{input1_data_file_name}
@out output1_data  @uri file:{output1_data_file_name}
@out log1_data @uri file:{log1_data_file_name}
create log file
@log {timestamp} Reading input records from {input1_data_file_name}
@begin read_scientificName
@param local_authority_source @uri {local_authority_source_file_name}
@call fuzzymatch
@out local_authority_source_scientificName_lst
create CSV reader for local_authority_source records
fieldnames/keys of original input data (dictionary)
find corresponding column position for specified header
iterate over local_authority_source data records
find values of specific fields
@end read_scientificName
@begin read_input1_data_records
@in input1_data @uri file:{input1_data_file_name}
@out original_scientificName @as scientificName
@out original_authorship @as authorship
@out original_catalogNumber @as catalogNumber
@out original_others @as others
create CSV reader for input records
iterate over input data records
open file for storing output data if not already open
extract values of fields to be validated
@log {timestamp} Reading input record {original_catalogNumber}
@end read_input1_data_records
@begin find_matching_local_authority_source_record
@in original_scientificName @as scientificName
@param local_authority_source_scientificName_lst
@call exactmatch
@OUT matching_local_authority_source_record
first try exact match of the scientific name against local_authority_source
@log {timestamp} Trying {source_type} {source_used} {matching_method} match for {field_name}: {original_scientificName}
@log {timestamp} {source_used} {matching_method} match was {MATCHING_RESULT}
otherwise try a fuzzy match
@log {timestamp} EXACT match FAILED.
@log {timestamp} Trying {source_used} {matching_method_fuzzy} match for scientific name: {original_scientificName}
@log {timestamp}  local_authority_source FUZZY match FAILED.
@end find_matching_local_authority_source_record
########################################################
reject the currect record if not matched successfully against local_authority_source
@log {timestamp} REJECTED record {original_catalogNumber}
write output record to output file
skip to processing of next record in input file
############################################################
@begin update_scientificName
@in original_scientificName @as scientificName
@in matching_local_authority_source_record
@out updated_scientificName
get scientific name from local_authority_source record if the taxon name match was fuzzy
@end update_scientificName
####################################################################
@begin update_authorship
@in matching_local_authority_source_record
@in original_authorship @as authorship
@out updated_authorship
get the scientific name authorship from the local_authority_source record if different from input record
@end update_authorship
####################################################################
compose_output1_record
@log {timestamp} UPDATING scientific name from {original_scientificName} to {updated_scientificName}
@log {timestamp} UPDATING scientific name authorship from {original_authorship} to {updated_authorship}
####################################################################
@begin write_log1_data
@param input1_data_file_name  @uri file:{input1_data_file_name}
@param original_catalogNumber @as catalogNumber
@param local_authority_source @uri file:{local_authority_source_file_name}
@in original_scientificName @as scientificName
@in original_authorship @as authorship
@in updated_scientificName
@in updated_authorship
@out log1_data @uri file:{log1_data_file_name}
@log {timestamp} ACCEPTED record {original_catalogNumber}
@end write_log1_data
write output record to output file
@begin write_output1_data
@in input1_data @uri file:{input1_data_file_name}
@in updated_scientificName
@in updated_authorship
@out output1_data  @uri file:{output1_data_file_name}
@log {timestamp} ACCEPTED record {original_catalogNumber}
@end write_output1_data
@log {timestamp} Wrote {accepted_record_count} accepted records to {output1_data_file_name}
@log {timestamp} Wrote {rejected_record_count} rejected records to {output1_data_file_name}
@end validate_scientificName_field_of_data
@begin validate_evenDate_field_of_data
@in output1_data  @uri file:{output1_data_file_name}
@out output2_data  @uri file:{output2_data_file_name}
@out log2_data @uri file:{log2_data_file_name}
create log file
@log {timestamp} Reading input records from {input2_data_file_name}
create CSV reader for input records
@begin read_input2_data_records
@in input2_data  @uri file:{output1_data_file_name}
@out original2_eventDate @as eventDate
@out original2_catalogNumber @as catalogNumber
@out original2_others @as others
iterate over input data records
open file for storing output data if not already open
extract values of fields to be validated
@log {timestamp} Reading input record {original2_catalogNumber}
@end read_input2_data_records
@begin clean_eventDate
@in original2_eventDate @as eventDate
@out updated2_eventDate @as updated_eventDate
reject the currect record if no value
@log {timestamp} Trying validating event date: {original2_eventDate}
@log {timestamp} Checking ISO date format (YYYY-MM-DD) for event date: '{original2_eventDate}'
date format: xxxx-xx-xx
date format: xxxx-xx-xx/xxxx-xx-xx
date format: xx/xx/xx
@log {timestamp} Not compliant with ISO date format.
@log {timestamp} Not compliant with ISO date format.
@end clean_eventDate
write into files
@log {timestamp} REJECTED record {original2_catalogNumber}
write output record to output file
skip to processing of next record in input file
@begin write_log2_data
@param input2_data_file_name  @uri file:{output1_data_file_name}
@param original2_catalogNumber @as catalogNumber
@in original2_eventDate @as eventDate
@in updated2_eventDate @as updated_eventDate
@out log2_data @uri file:{log2_data_file_name}
@log {timestamp} Updating event date format from '{original2_eventDate}' to '{updated2_eventDate}'
@log {timestamp} ACCEPTED record {original2_catalogNumber}
@end write_log2_data
@begin write_output2_data
@in input2_data
@in updated2_eventDate @as updated_eventDate
@out output2_data  @uri file:{output2_data_file_name}
@end write_output2_data
@log {timestamp} Compliant with ISO date format.
@log {timestamp} ACCEPTED record {original2_catalogNumber}.
@log {timestamp} Wrote {accepted2_record_count} accepted records to {output2_data_file_name}
@log {timestamp} Wrote {rejected2_record_count} rejected records to {rejected2_data_file_name}
@end validate_evenDate_field_of_data
@end clean_name_date_log
@begin exactmatch
@param lst
@param label_str
@return key
@return None
@end exactmatch
@begin fuzzymatch
@param lst
@param label_str
@return mat_dict
@end fuzzymatch
@begin timestamp
@param message
@return timestamp_message
@end timestamp
Demo of clean_name_date_log script
